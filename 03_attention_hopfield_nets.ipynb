{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hopfield Networks & the attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update rule from Modern Hopfield Networks:\n",
    "$$\n",
    "s^{new} = X {softmax}\\big(\\beta X^{T} s \\big)\n",
    "$$\n",
    "can be generalized to $S$ state patterns $\\Xi = (s_{1},...,s_{S})$:\n",
    "$$\n",
    "\\Xi^{new} = X {softmax}\\big(\\beta X^{T} \\Xi \\big)\n",
    "$$\n",
    "\n",
    "Considering $X^{T}$ as $N$ raw stored patterns $Y$ which are mapped to an *associative space* via $W_{K}$, and $\\Xi^{T}$ as $S$ raw state patterns $R$ which are mapped to an *associative space* via $W_{Q}$:\n",
    "$$\n",
    "Q = \\Xi^{T} = RW_{Q}\n",
    "$$\n",
    "$$\n",
    "K = X^{T} = YW_{K}\n",
    "$$\n",
    "$$\n",
    "\\beta = \\frac{1}{\\sqrt{d_{k}}}\n",
    "$$\n",
    "\n",
    "With this, we obtain:\n",
    "$$\n",
    "(Q^{new})^{T} = K^{T} {softmax}\\left(\\frac{1}{\\sqrt{d_{k}}} KQ^{T}\\right)\n",
    "$$\n",
    "$$\n",
    "Q^{new} = {softmax}\\left(\\frac{1}{\\sqrt{d_{k}}} QK^{T}\\right)K\n",
    "$$\n",
    "\n",
    "Projecting $Q^{new}$ via another projection $W_{V}$:\n",
    "$$\n",
    "Z = Q^{new}W_{V} = {softmax}\\left( \\frac{1}{\\sqrt{d_{k}}} QK^{T} \\right) KW_{V} = {softmax}\\left( \\frac{1}{\\sqrt{d_{k}}} QK^{T} \\right) V\n",
    "$$\n",
    "\n",
    "Transformer self-attention (auto-associative memories)..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
